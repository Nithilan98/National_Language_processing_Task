{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Filter_the _Resume.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        " \n",
        " \n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        " \n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(extract_text_from_pdf('Nithilaselvan.pdf'))  # noqa: T001"
      ],
      "metadata": {
        "id": "a6Oy_C_LClot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt\n",
        "import nltk\n",
        " \n",
        "\n",
        " \n",
        "# you may read the database from a csv file or some other database\n",
        "SKILLS_DB = [\n",
        "             'feature enginnering',\n",
        "             'python',\n",
        "    'machine learning',\n",
        "    'data science',\n",
        "    'nlp',\n",
        "    'feature enginnering'\n",
        "    'web development'\n",
        "    'python'\n",
        "]\n",
        " \n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        " \n",
        "def extract_text_from_docx(docx_path):\n",
        "    txt = docx2txt.process(docx_path)\n",
        "    if txt:\n",
        "        return txt.replace('\\t', ' ')\n",
        "    return None\n",
        " \n",
        " \n",
        "def extract_skills(input_text):\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
        " \n",
        "    # remove the stop words\n",
        "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
        " \n",
        "    # remove the punctuation\n",
        "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
        " \n",
        "    # generate bigrams and trigrams (such as artificial intelligence)\n",
        "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
        " \n",
        "    # we create a set to keep the results in.\n",
        "    found_skills = set()\n",
        " \n",
        "    # we search for each token in our skills database\n",
        "    for token in filtered_tokens:\n",
        "        if token.lower() in SKILLS_DB:\n",
        "            found_skills.add(token)\n",
        " \n",
        "    # we search for each bigram and trigram in our skills database\n",
        "    for ngram in bigrams_trigrams:\n",
        "        if ngram.lower() in SKILLS_DB:\n",
        "            found_skills.add(ngram)\n",
        " \n",
        "    return found_skills\n",
        " \n",
        " \n",
        "if __name__ == '__main__':\n",
        "    text = extract_text_from_pdf('Nithilaselvan.pdf')\n",
        "    skills = list(extract_skills(text))\n",
        "    skill = [\"Data science\",'NLP']\n",
        "    \n",
        "    check =  all(item in skills for item in skill)\n",
        "\n",
        "    if check is True:\n",
        "      print(\"Your Resume sorted for further round\")\n",
        "    else:\n",
        "      print(\"Your Resume not move to next round\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLFqCEUdC1H8",
        "outputId": "a7173a24-ba37-45bb-d61c-a694a0c9a370"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Resume sorted for further round\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt\n",
        "import nltk\n",
        " \n",
        "\n",
        " \n",
        "# you may read the database from a csv file or some other database\n",
        "SKILLS_DB = [\n",
        "             'feature enginnering',\n",
        "             'python',\n",
        "    'machine learning',\n",
        "    'data science',\n",
        "    'nlp',\n",
        "    'feature enginnering'\n",
        "    'web development'\n",
        "    'python'\n",
        "]\n",
        " \n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        " \n",
        "def extract_text_from_docx(docx_path):\n",
        "    txt = docx2txt.process(docx_path)\n",
        "    if txt:\n",
        "        return txt.replace('\\t', ' ')\n",
        "    return None\n",
        " \n",
        " \n",
        "def extract_skills(input_text):\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
        " \n",
        "    # remove the stop words\n",
        "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
        " \n",
        "    # remove the punctuation\n",
        "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
        " \n",
        "    # generate bigrams and trigrams (such as artificial intelligence)\n",
        "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
        " \n",
        "    # we create a set to keep the results in.\n",
        "    found_skills = set()\n",
        " \n",
        "    # we search for each token in our skills database\n",
        "    for token in filtered_tokens:\n",
        "        if token.lower() in SKILLS_DB:\n",
        "            found_skills.add(token)\n",
        " \n",
        "    # we search for each bigram and trigram in our skills database\n",
        "    for ngram in bigrams_trigrams:\n",
        "        if ngram.lower() in SKILLS_DB:\n",
        "            found_skills.add(ngram)\n",
        " \n",
        "    return found_skills\n",
        " \n",
        " \n",
        "if __name__ == '__main__':\n",
        "    text = extract_text_from_pdf('Nithilaselvan.pdf')\n",
        "    skills = list(extract_skills(text))\n",
        "    skill = ['web development']\n",
        "    \n",
        "    check =  all(item in skills for item in skill)\n",
        "\n",
        "    if check is True:\n",
        "      print(\"Your Resume sorted for further round\")\n",
        "    else:\n",
        "      print(\"Your Resume not move to next round\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDeiSfINKQSG",
        "outputId": "0db10dc0-75e9-46bd-c578-d6a8cda3c9ed"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Resume not move to next round\n"
          ]
        }
      ]
    }
  ]
}